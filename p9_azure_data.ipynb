{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af9e2ca",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Connect-to-workspace\" data-toc-modified-id=\"Connect-to-workspace-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Connect to workspace</a></span></li><li><span><a href=\"#Define-Datastore\" data-toc-modified-id=\"Define-Datastore-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Define Datastore</a></span><ul class=\"toc-item\"><li><span><a href=\"#Up-load-file-(folder)-to-Datastore\" data-toc-modified-id=\"Up-load-file-(folder)-to-Datastore-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Up load file (folder) to Datastore</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9611b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Run, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf41ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core import Environment, ScriptRunConfig, Experiment\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b7074bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e6b84",
   "metadata": {},
   "source": [
    "## Connect to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c319bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.35.0 to work with projet_7\n"
     ]
    }
   ],
   "source": [
    "#import workspace from config.json\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972d186",
   "metadata": {},
   "source": [
    "## Define Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208ff91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"dataset_projet7\",\n",
      "  \"container_name\": \"dataset-projet7\",\n",
      "  \"account_name\": \"stockageprojet7opcr\",\n",
      "  \"protocol\": \"https\",\n",
      "  \"endpoint\": \"core.windows.net\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "default_ds = ws.get_default_datastore()\n",
    "print(default_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09adfea9",
   "metadata": {},
   "source": [
    "### Up load file (folder) to Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e8c3ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\favre\\\\projet_9\\\\gtfine'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = os.path.abspath(\"gtfine\")\n",
    "filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7255bce",
   "metadata": {},
   "source": [
    "In azureCLI:\n",
    "\n",
    "az storage blob upload-batch --destination dataset-projet7 --source C:\\\\Users\\\\favre\\\\projet_9\\\\photo --account-key ujARUiYsDABZ9UTCzWwzdwaNDscT3dIUsZ/EMvCtx38XhSvZ5Q5Ks5hKn8YnGc5Q+1P9jrMmLR6vl70nQdzrBA==  --account-name stockageprojet7opcr  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f777f",
   "metadata": {},
   "source": [
    "## up date env from yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500dd327",
   "metadata": {},
   "source": [
    "conda env update --name myenv --file local.yml --prune  \n",
    "conda env update --name proj9 --file env-p9.yml --prune \n",
    "conda env update -p d:\\\\anaconda\\\\envs -f env-p9 --prune\n",
    "  \n",
    " --prune uninstalls dependencies which were removed from local.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697697c",
   "metadata": {},
   "source": [
    "## Compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e87809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "cluster_name = 'cluster-projet7'\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df9ecf",
   "metadata": {},
   "source": [
    "## Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52db82f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No Python version provided, defaulting to \"3.6.2\"\n"
     ]
    }
   ],
   "source": [
    "#create environment from yml file\n",
    "env_p9 = Environment.from_conda_specification(\"env_p9\", 'training_azure/env-p9.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205dcaa7",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c015f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training_azure/data_augmentation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_azure/data_augmentation.py\n",
    "print('print importing lib...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46c9c4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_azure/training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_azure/training.py\n",
    "print('print importing lib...')\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "from azureml.core import Dataset\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import joblib\n",
    "import cv2\n",
    "\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, UpSampling2D\n",
    "from tensorflow.python.keras.optimizers import Adadelta, Nadam\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.utils import multi_gpu_model, plot_model\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.losses import binary_crossentropy\n",
    "from tensorflow.python.keras.utils import Sequence\n",
    "from tensorflow.python.keras.callbacks import Callback\n",
    "\n",
    "from dilatednet import DilatedNet\n",
    "from multiclassunet import Unet\n",
    "\n",
    "print('lib imported...')\n",
    "\n",
    "#get scripts arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--image-folder', type=str, dest='image_folder')\n",
    "parser.add_argument('--mask-folder', type=, dest='mask_folder')\n",
    "\n",
    "#set parameters\n",
    "batch_size = 2\n",
    "samples = 50000\n",
    "steps = samples//batch_size\n",
    "img_height, img_width = 256, 256\n",
    "classes = 8\n",
    "filters_n = 64\n",
    "\n",
    "#load data\n",
    "print('data...')\n",
    "mask_path = run.input_datasets['mask']\n",
    "image_path = run.input_datasets['image']\n",
    "\n",
    "#divison of labelling\n",
    "cats = {'void': [0, 1, 2, 3, 4, 5, 6],\n",
    " 'flat': [7, 8, 9, 10],\n",
    " 'construction': [11, 12, 13, 14, 15, 16],\n",
    " 'object': [17, 18, 19, 20],\n",
    " 'nature': [21, 22],\n",
    " 'sky': [23],\n",
    " 'human': [24, 25],\n",
    " 'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]}\n",
    "\n",
    "#mounted point to directory\n",
    "image_dir = mask_path\n",
    "mask_dir = image_path\n",
    "mask = 'labelIds'\n",
    "\n",
    "#extract list of pictures \n",
    "print('making picture list...')\n",
    "image_list = []\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for name in files:\n",
    "        image_list.append(os.path.join(root, name))\n",
    "\n",
    "#extract mask with label\n",
    "mask_list_l = []\n",
    "for root, dirs, files in os.walk(mask_dir):\n",
    "    for name in files:\n",
    "        mask_list_l.append(os.path.join(root, name))\n",
    "\n",
    "mask_list = [m for m in mask_list_l if mask in m]\n",
    "\n",
    "print(\"class gen...\")\n",
    "\n",
    "class seg_gen(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #make a array of length batch size containing random position of photo\n",
    "        idx = np.random.randint(0, 10, batch_size)\n",
    "        batch_x, batch_y = [], []\n",
    "        drawn = 0\n",
    "        \n",
    "        for i in idx:\n",
    "            #import original image /255 to normalize and avoid big number for compute power\n",
    "            _image = image.img_to_array(image.load_img(f'{image_list[i]}', target_size=(img_height, img_width)))/255.\n",
    "            #import mask\n",
    "            img = image.img_to_array(image.load_img(f'{mask_list[i]}', grayscale=True, target_size=(img_height, img_width)))\n",
    "            #assess number of different label\n",
    "            labels = np.unique(img)\n",
    "            #ignore picture withtout features\n",
    "            if len(labels) < 3:\n",
    "                idx = np.random.randint(0, 50000, batch_size-drawn)\n",
    "                continue\n",
    "            img = np.squeeze(img)\n",
    "            #create a tensor of dimension image with one plan for each category\n",
    "            mask = np.zeros((img.shape[0], img.shape[1], 8))\n",
    "            for i in range(-1, 34):\n",
    "                if i in cats['void']:\n",
    "                    mask[:,:,0] = np.logical_or(mask[:,:,0],(img==i))\n",
    "                elif i in cats['flat']:\n",
    "                    mask[:,:,1] = np.logical_or(mask[:,:,1],(img==i))\n",
    "                elif i in cats['construction']:\n",
    "                    mask[:,:,2] = np.logical_or(mask[:,:,2],(img==i))\n",
    "                elif i in cats['object']:\n",
    "                    mask[:,:,3] = np.logical_or(mask[:,:,3],(img==i))\n",
    "                elif i in cats['nature']:\n",
    "                    mask[:,:,4] = np.logical_or(mask[:,:,4],(img==i))\n",
    "                elif i in cats['sky']:\n",
    "                    mask[:,:,5] = np.logical_or(mask[:,:,5],(img==i))\n",
    "                elif i in cats['human']:\n",
    "                    mask[:,:,6] = np.logical_or(mask[:,:,6],(img==i))\n",
    "                elif i in cats['vehicle']:\n",
    "                    mask[:,:,7] = np.logical_or(mask[:,:,7],(img==i))\n",
    "            mask = np.resize(mask,(img_height*img_width, 8))\n",
    "            batch_y.append(mask)\n",
    "            batch_x.append(_image)\n",
    "            drawn += 1\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "    \n",
    "print('coef and loss...')\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def total_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + (3*dice_loss(y_true, y_pred))\n",
    "    return loss\\\n",
    "\n",
    "print('model...')\n",
    "\n",
    "unet = DilatedNet(256, 256, 8,use_ctx_module=True, bn=True)\n",
    "unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[dice_coeff, 'accuracy'])\n",
    "tb = TensorBoard(log_dir='logs', write_graph=True)\n",
    "mc = ModelCheckpoint(mode='max', filepath='models/pdilated.h5', monitor='acc', save_best_only='True', save_weights_only='True', verbose=1)\n",
    "es = EarlyStopping(mode='max', monitor='acc', patience=6, verbose=1)\n",
    "callbacks = [tb, mc, es]\n",
    "\n",
    "print('making input...')\n",
    "train_gen = seg_gen(image_list[:10], mask_list[:10], batch_size)\n",
    "\n",
    "print('fit...')\n",
    "unet.fit_generator(train_gen, epochs=5, callbacks=callbacks)\n",
    "\n",
    "print('Saving final weights')\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "model_file = os.path.join('outputs', 'dilated.h5')\n",
    "unet.save_weights(model_file)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91dee75",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba14bde2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d88bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "#experiment folder\n",
    "experiment_folder = 'training_azure'\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "#assign compute\n",
    "pipeline_run_config.target = training_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = env_p9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c856a6ad",
   "metadata": {},
   "source": [
    "## Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7695171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Get the training dataset\n",
    "image_ds = ws.datasets.get(\"image\")\n",
    "mask_ds = ws.datasets.get('cityscape_train')\n",
    "\n",
    "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
    "#with no specification in OutputFileDatasetConfig for destination it will be in workspaceblobstore datastore\n",
    "augmented_data = OutputFileDatasetConfig(\"augmented_data\")\n",
    "\n",
    "#step1, run the data prep script\n",
    "prep_step = PythonScriptStep(name = \"Data augmentation\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"data_augmentation.py\",\n",
    "                                arguments = ['--augmented_data', augmented_data,\n",
    "                                             '--input-data', image_ds.as_named_input('image').as_mount(),\n",
    "                                            '--input-data2', mask_ds.as_named_input('mask').as_mount()],\n",
    "                                compute_target = training_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "# Step 2, run the training script\n",
    "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"training.py\",\n",
    "                                arguments = ['--training-data', augmented_data.as_input()],\n",
    "                                compute_target = training_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76d9e9",
   "metadata": {},
   "source": [
    "## Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9368bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [prep_step, train_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace=ws, name = 'recommender-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "\n",
    "\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb33a9",
   "metadata": {},
   "source": [
    "## Examine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6f409e",
   "metadata": {},
   "source": [
    "see projet 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49c4db",
   "metadata": {},
   "source": [
    "## Script testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6079d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'image-segmentation-unet'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3def0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training dataset\n",
    "image_ds = ws.datasets.get(\"image\")\n",
    "mask_ds = ws.datasets.get('mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "439e24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "args = ['--image-folder', image_ds.as_named_input('image').as_mount(),\n",
    "        '--mask-folder', mask_ds.as_named_input('mask').as_mount()]\n",
    "\n",
    "src = ScriptRunConfig(source_directory=\"training_azure\",\n",
    "                      script='training.py', \n",
    "                      arguments=args,\n",
    "                      compute_target=training_cluster,\n",
    "                      environment=env_p9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7522401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: image-segmentation-unet_1635443357_62f93dbd\n",
      "Web View: https://ml.azure.com/runs/image-segmentation-unet_1635443357_62f93dbd?wsid=/subscriptions/b9053cbf-be55-4e83-8c03-d6b0eb90cb5a/resourcegroups/Projet_7/workspaces/projet_7&tid=33e47288-d1e1-43e8-b65b-4ba7bfd37a9f\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "2021/10/28 17:49:26 Downloading source code...\n",
      "2021/10/28 17:49:26 Finished downloading source code\n",
      "2021/10/28 17:49:27 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2021/10/28 17:49:27 Successfully set up Docker network: acb_default_network\n",
      "2021/10/28 17:49:27 Setting up Docker configuration...\n",
      "2021/10/28 17:49:28 Successfully set up Docker configuration\n",
      "2021/10/28 17:49:28 Logging in to registry: 38d02f2005824c85859d3a5c11c9a143.azurecr.io\n",
      "2021/10/28 17:49:28 Successfully logged into 38d02f2005824c85859d3a5c11c9a143.azurecr.io\n",
      "2021/10/28 17:49:28 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/10/28 17:49:28 Scanning for dependencies...\n",
      "2021/10/28 17:49:29 Successfully scanned dependencies\n",
      "2021/10/28 17:49:29 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "\n",
      "Step 1/19 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210922.v1@sha256:bfed4edd2085c7fa221827c7ea4d1dc8c48fd52d64b9411260bf94f7f6fae31a\n",
      "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210922.v1@sha256:bfed4edd2085c7fa221827c7ea4d1dc8c48fd52d64b9411260bf94f7f6fae31a: Pulling from azureml/openmpi3.1.2-ubuntu18.04\n",
      "e4ca327ec0e7: Already exists\n",
      "f0fb8b64b41b: Pulling fs layer\n",
      "e43ee38068bf: Pulling fs layer\n",
      "409df78264bc: Pulling fs layer\n",
      "a2eb44ae9dc0: Pulling fs layer\n",
      "b8ff7afa1c52: Pulling fs layer\n",
      "d92dd21f7e9a: Pulling fs layer\n",
      "965946e36f3d: Pulling fs layer\n",
      "9d3ce4a2dac8: Pulling fs layer\n",
      "a2eb44ae9dc0: Waiting\n",
      "b8ff7afa1c52: Waiting\n",
      "d92dd21f7e9a: Waiting\n",
      "965946e36f3d: Waiting\n",
      "9d3ce4a2dac8: Waiting\n",
      "409df78264bc: Verifying Checksum\n",
      "409df78264bc: Download complete\n",
      "e43ee38068bf: Verifying Checksum\n",
      "e43ee38068bf: Download complete\n",
      "b8ff7afa1c52: Verifying Checksum\n",
      "b8ff7afa1c52: Download complete\n",
      "a2eb44ae9dc0: Verifying Checksum\n",
      "a2eb44ae9dc0: Download complete\n",
      "f0fb8b64b41b: Verifying Checksum\n",
      "f0fb8b64b41b: Download complete\n",
      "965946e36f3d: Verifying Checksum\n",
      "965946e36f3d: Download complete\n",
      "9d3ce4a2dac8: Verifying Checksum\n",
      "9d3ce4a2dac8: Download complete\n",
      "d92dd21f7e9a: Verifying Checksum\n",
      "d92dd21f7e9a: Download complete\n",
      "f0fb8b64b41b: Pull complete\n",
      "e43ee38068bf: Pull complete\n",
      "409df78264bc: Pull complete\n",
      "a2eb44ae9dc0: Pull complete\n",
      "b8ff7afa1c52: Pull complete\n",
      "d92dd21f7e9a: Pull complete\n",
      "965946e36f3d: Pull complete\n",
      "9d3ce4a2dac8: Pull complete\n",
      "Digest: sha256:bfed4edd2085c7fa221827c7ea4d1dc8c48fd52d64b9411260bf94f7f6fae31a\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210922.v1@sha256:bfed4edd2085c7fa221827c7ea4d1dc8c48fd52d64b9411260bf94f7f6fae31a\n",
      " ---> 9e882d6546b4\n",
      "Step 2/19 : USER root\n",
      " ---> Running in 26ce45d1ff29\n",
      "Removing intermediate container 26ce45d1ff29\n",
      " ---> d1056747f43a\n",
      "Step 3/19 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 9b3e5e48a7c8\n",
      "Removing intermediate container 9b3e5e48a7c8\n",
      " ---> 50d447378593\n",
      "Step 4/19 : WORKDIR /\n",
      " ---> Running in 8e60d59195c1\n",
      "Removing intermediate container 8e60d59195c1\n",
      " ---> c6ab8c4c628b\n",
      "Step 5/19 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 2cfb74377343\n",
      "Step 6/19 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 3f9573b782bf\n",
      "Removing intermediate container 3f9573b782bf\n",
      " ---> cbbf2ffe226b\n",
      "Step 7/19 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> d782e7c97027\n",
      "Step 8/19 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_8f31e611a4535743ce7e65fb2516bcda -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 231447819abb\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "absl-py-0.15.0       | 98 KB     |            |   0% \n",
      "absl-py-0.15.0       | 98 KB     | #6         |  16% \n",
      "absl-py-0.15.0       | 98 KB     | ########## | 100% \n",
      "\n",
      "pip-21.3.1           | 1.2 MB    |            |   0% \n",
      "pip-21.3.1           | 1.2 MB    | ########## | 100% \n",
      "pip-21.3.1           | 1.2 MB    | ########## | 100% \n",
      "\n",
      "pygments-2.10.0      | 760 KB    |            |   0% \n",
      "pygments-2.10.0      | 760 KB    | ########## | 100% \n",
      "pygments-2.10.0      | 760 KB    | ########## | 100% \n",
      "\n",
      "libwebp-base-1.2.1   | 845 KB    |            |   0% \n",
      "libwebp-base-1.2.1   | 845 KB    | ########## | 100% \n",
      "libwebp-base-1.2.1   | 845 KB    | ########## | 100% \n",
      "\n",
      "xorg-libxdmcp-1.1.3  | 19 KB     |            |   0% \n",
      "xorg-libxdmcp-1.1.3  | 19 KB     | ########## | 100% \n",
      "\n",
      "importlib-metadata-4 | 32 KB     |            |   0% \n",
      "importlib-metadata-4 | 32 KB     | ########## | 100% \n",
      "\n",
      "xorg-inputproto-2.3. | 19 KB     |            |   0% \n",
      "xorg-inputproto-2.3. | 19 KB     | ########## | 100% \n",
      "\n",
      "markdown-3.3.4       | 67 KB     |            |   0% \n",
      "markdown-3.3.4       | 67 KB     | ########## | 100% \n",
      "\n",
      "pyrsistent-0.17.3    | 89 KB     |            |   0% \n",
      "pyrsistent-0.17.3    | 89 KB     | ########## | 100% \n",
      "\n",
      "xorg-libsm-1.2.3     | 26 KB     |            |   0% \n",
      "xorg-libsm-1.2.3     | 26 KB     | ########## | 100% \n",
      "\n",
      "keras-applications-1 | 30 KB     |            |   0% \n",
      "keras-applications-1 | 30 KB     | ########## | 100% \n",
      "\n",
      "glib-2.56.2          | 4.7 MB    |            |   0% \n",
      "glib-2.56.2          | 4.7 MB    | ########## | 100% \n",
      "glib-2.56.2          | 4.7 MB    | ########## | 100% \n",
      "\n",
      "libgfortran-ng-11.2. | 19 KB     |            |   0% \n",
      "libgfortran-ng-11.2. | 19 KB     | ########## | 100% \n",
      "\n",
      "grpcio-1.16.0        | 1.0 MB    |            |   0% \n",
      "grpcio-1.16.0        | 1.0 MB    | ########## | 100% \n",
      "grpcio-1.16.0        | 1.0 MB    | ########## | 100% \n",
      "\n",
      "decorator-5.1.0      | 11 KB     |            |   0% \n",
      "decorator-5.1.0      | 11 KB     | ########## | 100% \n",
      "\n",
      "mako-1.1.5           | 58 KB     |            |   0% \n",
      "mako-1.1.5           | 58 KB     | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 86 KB     |            |   0% \n",
      "zlib-1.2.11          | 86 KB     | ########## | 100% \n",
      "\n",
      "jupyter_core-4.8.1   | 78 KB     |            |   0% \n",
      "jupyter_core-4.8.1   | 78 KB     | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-11.2.0  | 4.2 MB    |            |   0% \n",
      "libstdcxx-ng-11.2.0  | 4.2 MB    | ########## | 100% \n",
      "libstdcxx-ng-11.2.0  | 4.2 MB    | ########## | 100% \n",
      "\n",
      "openjpeg-2.4.0       | 444 KB    |            |   0% \n",
      "openjpeg-2.4.0       | 444 KB    | ########## | 100% \n",
      "\n",
      "parso-0.7.1          | 70 KB     |            |   0% \n",
      "parso-0.7.1          | 70 KB     | ########## | 100% \n",
      "\n",
      "xorg-xextproto-7.3.0 | 28 KB     |            |   0% \n",
      "xorg-xextproto-7.3.0 | 28 KB     | ########## | 100% \n",
      "\n",
      "attrs-21.2.0         | 44 KB     |            |   0% \n",
      "attrs-21.2.0         | 44 KB     | ########## | 100% \n",
      "\n",
      "jupyter_client-7.0.6 | 87 KB     |            |   0% \n",
      "jupyter_client-7.0.6 | 87 KB     | ########## | 100% \n",
      "\n",
      "lcms2-2.12           | 443 KB    |            |   0% \n",
      "lcms2-2.12           | 443 KB    | ########## | 100% \n",
      "\n",
      "pcre-8.45            | 253 KB    |            |   0% \n",
      "pcre-8.45            | 253 KB    | ########## | 100% \n",
      "\n",
      "freetype-2.10.4      | 890 KB    |            |   0% \n",
      "freetype-2.10.4      | 890 KB    | ########## | 100% \n",
      "freetype-2.10.4      | 890 KB    | ########## | 100% \n",
      "\n",
      "ipykernel-5.5.5      | 166 KB    |            |   0% \n",
      "ipykernel-5.5.5      | 166 KB    | ########## | 100% \n",
      "\n",
      "libgpuarray-0.7.6    | 245 KB    |            |   0% \n",
      "libgpuarray-0.7.6    | 245 KB    | ########## | 100% \n",
      "\n",
      "sqlite-3.13.0        | 4.9 MB    |            |   0% \n",
      "sqlite-3.13.0        | 4.9 MB    | ########## | 100% \n",
      "sqlite-3.13.0        | 4.9 MB    | ########## | 100% \n",
      "\n",
      "libsodium-1.0.18     | 366 KB    |            |   0% \n",
      "libsodium-1.0.18     | 366 KB    | ########## | 100% \n",
      "\n",
      "jsonschema-4.1.2     | 54 KB     |            |   0% \n",
      "jsonschema-4.1.2     | 54 KB     | ########## | 100% \n",
      "\n",
      "pandas-1.1.5         | 11.3 MB   |            |   0% \n",
      "pandas-1.1.5         | 11.3 MB   | #######8   |  79% \n",
      "Run ID: cbh timed out after 1h30m0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: image-segmentation-unet_1635443357_62f93dbd\n",
      "Web View: https://ml.azure.com/runs/image-segmentation-unet_1635443357_62f93dbd?wsid=/subscriptions/b9053cbf-be55-4e83-8c03-d6b0eb90cb5a/resourcegroups/Projet_7/workspaces/projet_7&tid=33e47288-d1e1-43e8-b65b-4ba7bfd37a9f\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Image build failed. For more details, check log file azureml-logs/20_image_build_log.txt.\",\n        \"messageFormat\": \"Image build failed. For more details, check log file {ArtifactPath}.\",\n        \"messageParameters\": {\n            \"ArtifactPath\": \"azureml-logs/20_image_build_log.txt\"\n        },\n        \"details\": [],\n        \"innerError\": {\n            \"code\": \"BadArgument\",\n            \"innerError\": {\n                \"code\": \"ImageBuildFailure\"\n            }\n        }\n    },\n    \"correlation\": {\n        \"operation\": \"891cbde40faf7644bd6284670b91e5e4\",\n        \"request\": \"efc80990c64b9352\"\n    },\n    \"environment\": \"westeurope\",\n    \"location\": \"westeurope\",\n    \"time\": \"2021-10-28T19:27:53.046434Z\",\n    \"componentName\": \"execution-worker\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Image build failed. For more details, check log file azureml-logs/20_image_build_log.txt.\\\",\\n        \\\"messageFormat\\\": \\\"Image build failed. For more details, check log file {ArtifactPath}.\\\",\\n        \\\"messageParameters\\\": {\\n            \\\"ArtifactPath\\\": \\\"azureml-logs/20_image_build_log.txt\\\"\\n        },\\n        \\\"details\\\": [],\\n        \\\"innerError\\\": {\\n            \\\"code\\\": \\\"BadArgument\\\",\\n            \\\"innerError\\\": {\\n                \\\"code\\\": \\\"ImageBuildFailure\\\"\\n            }\\n        }\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": \\\"891cbde40faf7644bd6284670b91e5e4\\\",\\n        \\\"request\\\": \\\"efc80990c64b9352\\\"\\n    },\\n    \\\"environment\\\": \\\"westeurope\\\",\\n    \\\"location\\\": \\\"westeurope\\\",\\n    \\\"time\\\": \\\"2021-10-28T19:27:53.046434Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23624/3655525637.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\proj9\\lib\\site-packages\\azureml\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[0;32m    827\u001b[0m                     \u001b[0mfile_handle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m                     \u001b[0mwait_post_processing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwait_post_processing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 829\u001b[1;33m                     raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    830\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\proj9\\lib\\site-packages\\azureml\\core\\run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[1;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                 \u001b[0mfile_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m         \u001b[0mfile_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Image build failed. For more details, check log file azureml-logs/20_image_build_log.txt.\",\n        \"messageFormat\": \"Image build failed. For more details, check log file {ArtifactPath}.\",\n        \"messageParameters\": {\n            \"ArtifactPath\": \"azureml-logs/20_image_build_log.txt\"\n        },\n        \"details\": [],\n        \"innerError\": {\n            \"code\": \"BadArgument\",\n            \"innerError\": {\n                \"code\": \"ImageBuildFailure\"\n            }\n        }\n    },\n    \"correlation\": {\n        \"operation\": \"891cbde40faf7644bd6284670b91e5e4\",\n        \"request\": \"efc80990c64b9352\"\n    },\n    \"environment\": \"westeurope\",\n    \"location\": \"westeurope\",\n    \"time\": \"2021-10-28T19:27:53.046434Z\",\n    \"componentName\": \"execution-worker\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Image build failed. For more details, check log file azureml-logs/20_image_build_log.txt.\\\",\\n        \\\"messageFormat\\\": \\\"Image build failed. For more details, check log file {ArtifactPath}.\\\",\\n        \\\"messageParameters\\\": {\\n            \\\"ArtifactPath\\\": \\\"azureml-logs/20_image_build_log.txt\\\"\\n        },\\n        \\\"details\\\": [],\\n        \\\"innerError\\\": {\\n            \\\"code\\\": \\\"BadArgument\\\",\\n            \\\"innerError\\\": {\\n                \\\"code\\\": \\\"ImageBuildFailure\\\"\\n            }\\n        }\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": \\\"891cbde40faf7644bd6284670b91e5e4\\\",\\n        \\\"request\\\": \\\"efc80990c64b9352\\\"\\n    },\\n    \\\"environment\\\": \\\"westeurope\\\",\\n    \\\"location\\\": \\\"westeurope\\\",\\n    \\\"time\\\": \\\"2021-10-28T19:27:53.046434Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "run = exp.submit(config=src)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4968a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
