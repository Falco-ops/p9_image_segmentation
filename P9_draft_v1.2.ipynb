{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377d6e87",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c6dc809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcea6c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17f50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f10f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da9e6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow\n",
    "from tensorflow.python.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8169b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, UpSampling2D\n",
    "from tensorflow.python.keras.optimizers import Adadelta, Nadam\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.utils import multi_gpu_model, plot_model\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996474e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.losses import binary_crossentropy\n",
    "from tensorflow.python.keras.utils import Sequence\n",
    "from tensorflow.python.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cf9e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dilatednet import DilatedNet\n",
    "from multiclassunet import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e532f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89c62b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb13a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4a47a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\PIL\\Image.py\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "print(Image.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6830337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\PIL\\Image.py\n"
     ]
    }
   ],
   "source": [
    "import Image\n",
    "print(Image.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a866e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\favre\\projet_9\\gtFine/train/hamburg/hamburg_000000_000042_gtFine_labelIds.png\n"
     ]
    }
   ],
   "source": [
    "dirname = os.getcwd()\n",
    "name = 'gtFine/train/hamburg/hamburg_000000_000042_gtFine_labelIds.png' \n",
    "filename = os.path.join(dirname, name)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd716d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "img = image.img_to_array(image.load_img(filename, grayscale=True, target_size=(256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecd2cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda env update --file env-p9.yml  --prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5de2012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 3.],\n",
       "        [ 3.],\n",
       "        [ 3.],\n",
       "        ...,\n",
       "        [ 3.],\n",
       "        [ 3.],\n",
       "        [ 3.]],\n",
       "\n",
       "       [[ 3.],\n",
       "        [ 2.],\n",
       "        [21.],\n",
       "        ...,\n",
       "        [ 2.],\n",
       "        [ 2.],\n",
       "        [ 3.]],\n",
       "\n",
       "       [[ 3.],\n",
       "        [ 2.],\n",
       "        [21.],\n",
       "        ...,\n",
       "        [ 2.],\n",
       "        [ 2.],\n",
       "        [ 3.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 3.],\n",
       "        [ 2.],\n",
       "        [ 2.],\n",
       "        ...,\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 3.]],\n",
       "\n",
       "       [[ 3.],\n",
       "        [ 2.],\n",
       "        [ 2.],\n",
       "        ...,\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 3.]],\n",
       "\n",
       "       [[ 3.],\n",
       "        [ 3.],\n",
       "        [ 3.],\n",
       "        ...,\n",
       "        [ 3.],\n",
       "        [ 3.],\n",
       "        [ 3.]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa85272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = np.squeeze(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fed6d0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  3.  3. ...  3.  3.  3.]\n",
      " [ 3.  2. 21. ...  2.  2.  3.]\n",
      " [ 3.  2. 21. ...  2.  2.  3.]\n",
      " ...\n",
      " [ 3.  2.  2. ...  1.  1.  3.]\n",
      " [ 3.  2.  2. ...  1.  1.  3.]\n",
      " [ 3.  3.  3. ...  3.  3.  3.]]\n"
     ]
    }
   ],
   "source": [
    "print(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b61202b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6352e28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260235ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  7.,  8., 11., 12., 13., 15., 17., 19.,\n",
       "       20., 21., 22., 23., 24., 25., 26., 27., 29., 32., 33.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.unique(img)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65f7acec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([91, 57,  6])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.randint(0, 100, 3)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb093d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#division of labelling\n",
    "cats = {'void': [0, 1, 2, 3, 4, 5, 6],\n",
    " 'flat': [7, 8, 9, 10],\n",
    " 'construction': [11, 12, 13, 14, 15, 16],\n",
    " 'object': [17, 18, 19, 20],\n",
    " 'nature': [21, 22],\n",
    " 'sky': [23],\n",
    " 'human': [24, 25],\n",
    " 'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2993f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name of directory\n",
    "image_dir = 'sample/sample_photo'\n",
    "mask_dir = 'sample/sample_mask'\n",
    "mask = 'labelIds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515cf8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 174\n"
     ]
    }
   ],
   "source": [
    "#extract list of pictures \n",
    "image_list = []\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for name in files:\n",
    "        image_list.append(os.path.join(root, name))\n",
    "\n",
    "#extract mask with label\n",
    "mask_list_l = []\n",
    "for root, dirs, files in os.walk(mask_dir):\n",
    "    for name in files:\n",
    "        mask_list_l.append(os.path.join(root, name))\n",
    "\n",
    "mask_list = [m for m in mask_list_l if mask in m]\n",
    "\n",
    "print(len(image_list), len(mask_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f05eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "image_dir = 'sample/sample_photo'\n",
    "mask_dir = 'sample/sample_mask'\n",
    "mask = '_labelIds'\n",
    "\n",
    "new_image_dir= 'test2/image'\n",
    "new_mask_dir= 'test2/mask'\n",
    "os.makedirs(new_image_dir, exist_ok=True)\n",
    "os.makedirs(new_mask_dir, exist_ok=True)\n",
    "reduction = '_leftImg8bit'\n",
    "\n",
    "#extract list of pictures \n",
    "image_list = []\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for name in files:        \n",
    "        old_path = os.path.join(root, name)\n",
    "        new_name = name.replace('_leftImg8bit', '')        \n",
    "        new_path = os.path.join(new_mask_dir, new_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            shutil.copy(old_path, new_path)\n",
    "        \n",
    "        image_list.append(new_path)\n",
    "        \n",
    "\n",
    "mask_list = []\n",
    "for root, dirs, files in os.walk(mask_dir):\n",
    "    for name in files:\n",
    "        if mask in name:\n",
    "            old_path = os.path.join(root, name)\n",
    "            new_name = name.replace('_gtFine_labelIds', '')        \n",
    "            new_path = os.path.join(new_image_dir, new_name)\n",
    "            if not os.path.exists(new_path):\n",
    "                shutil.copy(old_path, new_path)\n",
    "\n",
    "            mask_list.append(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb3f59b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample/sample_mask\\aachen\\aachen_000001_000019_gtFine_labelIds.png\n"
     ]
    }
   ],
   "source": [
    "nom = 'aachen_000000_000019_leftImg8bit.png'\n",
    "new = nom.replace('_leftImg8bit', '')\n",
    "print(mask_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3308633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "batch_size = 2\n",
    "samples = 50000\n",
    "steps = samples//batch_size\n",
    "img_height, img_width = 256, 256\n",
    "classes = 8\n",
    "filters_n = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae40876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "#test de getitem\n",
    "\n",
    "#make a array of length batch size containing random position of photo\n",
    "idx = np.random.randint(0, 2975, batch_size)\n",
    "for i in idx:\n",
    "    #import to array a normalize image\n",
    "    _image = image.img_to_array(image.load_img(f'{image_list[i]}', target_size=(img_height, img_width)))/255.\n",
    "    #import to array the mask\n",
    "    img = image.img_to_array(image.load_img(f'{mask_list[i]}', grayscale=True, target_size=(img_height, img_width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7672d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(test_image, test_mask):\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.set_title('Image')\n",
    "    ax.imshow(test_image)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 2)\n",
    "    ax1.set_title('GT_Mask')\n",
    "    ax1.imshow(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a03c63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  3.,  4.,  7.,  9., 11., 13., 17., 21., 23., 26.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.unique(img)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13c0911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "img = np.squeeze(img)\n",
    "#create empty tensor dimension img img and 1 per category (8)\n",
    "mask = np.zeros((img.shape[0], img.shape[1], 8))\n",
    "#iterate through sub category\n",
    "for i in range(-1, 34):\n",
    "    if i in cats['void']:\n",
    "        mask[:,:,0] = np.logical_or(mask[:,:,0],(img==i))\n",
    "    elif i in cats['flat']:\n",
    "        mask[:,:,1] = np.logical_or(mask[:,:,1],(img==i))\n",
    "    elif i in cats['construction']:\n",
    "        mask[:,:,2] = np.logical_or(mask[:,:,2],(img==i))\n",
    "    elif i in cats['object']:\n",
    "        mask[:,:,3] = np.logical_or(mask[:,:,3],(img==i))\n",
    "    elif i in cats['nature']:\n",
    "        mask[:,:,4] = np.logical_or(mask[:,:,4],(img==i))\n",
    "    elif i in cats['sky']:\n",
    "        mask[:,:,5] = np.logical_or(mask[:,:,5],(img==i))\n",
    "        print(mask[:,:,5])\n",
    "    elif i in cats['human']:\n",
    "        mask[:,:,6] = np.logical_or(mask[:,:,6],(img==i))\n",
    "    elif i in cats['vehicle']:\n",
    "        mask[:,:,7] = np.logical_or(mask[:,:,7],(img==i))\n",
    "        \n",
    "mask = np.resize(mask,(img_height*img_width, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4669730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8df8db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seg_gen(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #make a array of length batch size containing random position of photo\n",
    "        idx = np.random.randint(0, 10, batch_size)\n",
    "        batch_x, batch_y = [], []\n",
    "        drawn = 0\n",
    "        \n",
    "        for i in idx:\n",
    "            #import original image /255 to normalize and avoid big number for compute power\n",
    "            _image = image.img_to_array(image.load_img(f'{image_list[i]}', target_size=(img_height, img_width)))/255.\n",
    "            #import mask\n",
    "            img = image.img_to_array(image.load_img(f'{mask_list[i]}', grayscale=True, target_size=(img_height, img_width)))\n",
    "            #assess number of different label\n",
    "            labels = np.unique(img)\n",
    "            #ignore picture withtout features\n",
    "            if len(labels) < 3:\n",
    "                idx = np.random.randint(0, 50000, batch_size-drawn)\n",
    "                continue\n",
    "            img = np.squeeze(img)\n",
    "            #create a tensor of dimension image with one plan for each category\n",
    "            mask = np.zeros((img.shape[0], img.shape[1], 8))\n",
    "            for i in range(-1, 34):\n",
    "                if i in cats['void']:\n",
    "                    mask[:,:,0] = np.logical_or(mask[:,:,0],(img==i))\n",
    "                elif i in cats['flat']:\n",
    "                    mask[:,:,1] = np.logical_or(mask[:,:,1],(img==i))\n",
    "                elif i in cats['construction']:\n",
    "                    mask[:,:,2] = np.logical_or(mask[:,:,2],(img==i))\n",
    "                elif i in cats['object']:\n",
    "                    mask[:,:,3] = np.logical_or(mask[:,:,3],(img==i))\n",
    "                elif i in cats['nature']:\n",
    "                    mask[:,:,4] = np.logical_or(mask[:,:,4],(img==i))\n",
    "                elif i in cats['sky']:\n",
    "                    mask[:,:,5] = np.logical_or(mask[:,:,5],(img==i))\n",
    "                elif i in cats['human']:\n",
    "                    mask[:,:,6] = np.logical_or(mask[:,:,6],(img==i))\n",
    "                elif i in cats['vehicle']:\n",
    "                    mask[:,:,7] = np.logical_or(mask[:,:,7],(img==i))\n",
    "            mask = np.resize(mask,(img_height*img_width, 8))\n",
    "            batch_y.append(mask)\n",
    "            batch_x.append(_image)\n",
    "            drawn += 1\n",
    "        return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b5442df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def total_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + (3*dice_loss(y_true, y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f27e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . .Building DilatedNet. . . . .\n",
      ". . . . .Building network successful. . . . .\n"
     ]
    }
   ],
   "source": [
    "unet = DilatedNet(256, 256, 8,use_ctx_module=True, bn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9147bd",
   "metadata": {},
   "source": [
    "**multi_gpu_model**  \n",
    "Specifically, this function implements single-machine multi-GPU data parallelism. It works in the following way:\n",
    "\n",
    "Divide the model's input(s) into multiple sub-batches.\n",
    "Apply a model copy on each sub-batch. Every model copy is executed on a dedicated GPU.\n",
    "Concatenate the results (on CPU) into one big batch.\n",
    "E.g. if your batch_size is 64 and you use gpus=2, then we will divide the input into 2 sub-batches of 32 samples, process each sub-batch on one GPU, then return the full batch of 64 processed samples.\n",
    "\n",
    "This induces quasi-linear speedup on up to 8 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5f22740",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "To call `multi_gpu_model` with `gpus=4`, we expect the following devices to be available: ['/cpu:0', '/gpu:0', '/gpu:1', '/gpu:2', '/gpu:3']. However this machine only has: ['/cpu:0']. Try reducing `gpus`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19020/2975275868.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp_unet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti_gpu_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\proj9\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\multi_gpu_utils.py\u001b[0m in \u001b[0;36mmulti_gpu_model\u001b[1;34m(model, gpus, cpu_merge, cpu_relocation)\u001b[0m\n\u001b[0;32m    180\u001b[0m                        \u001b[1;34m'However this machine only has: %s. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                        'Try reducing `gpus`.' % (gpus, target_devices,\n\u001b[1;32m--> 182\u001b[1;33m                                                  available_devices))\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: To call `multi_gpu_model` with `gpus=4`, we expect the following devices to be available: ['/cpu:0', '/gpu:0', '/gpu:1', '/gpu:2', '/gpu:3']. However this machine only has: ['/cpu:0']. Try reducing `gpus`."
     ]
    }
   ],
   "source": [
    "\n",
    "p_unet = multi_gpu_model(unet, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8329272",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[dice_coeff, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c191c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='logs', write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecf1eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(mode='max', filepath='models/pdilated.h5', monitor='acc', save_best_only='True', save_weights_only='True', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f9e9675",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(mode='max', monitor='acc', patience=6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6284ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tb, mc, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43eb4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vizualize every callback\n",
    "vis = visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d98a26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = seg_gen(image_list[:10], mask_list[:10], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00b66953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/5 [=======================>......] - ETA: 14s - loss: 1.5345 - dice_coeff: 0.4493 - acc: 0.5204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\proj9\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: acc improved from -inf to 0.52880, saving model to models/pdilated.h5\n",
      "5/5 [==============================] - 75s 15s/step - loss: 1.5284 - dice_coeff: 0.4615 - acc: 0.5288\n",
      "Epoch 2/5\n",
      "4/5 [=======================>......] - ETA: 12s - loss: 0.8751 - dice_coeff: 0.6292 - acc: 0.6915\n",
      "Epoch 00002: acc improved from 0.52880 to 0.68309, saving model to models/pdilated.h5\n",
      "5/5 [==============================] - 63s 13s/step - loss: 0.8803 - dice_coeff: 0.6253 - acc: 0.6831\n",
      "Epoch 3/5\n",
      "4/5 [=======================>......] - ETA: 12s - loss: 0.7934 - dice_coeff: 0.6251 - acc: 0.7002\n",
      "Epoch 00003: acc improved from 0.68309 to 0.70419, saving model to models/pdilated.h5\n",
      "5/5 [==============================] - 67s 13s/step - loss: 0.7846 - dice_coeff: 0.6253 - acc: 0.7042\n",
      "Epoch 4/5\n",
      "4/5 [=======================>......] - ETA: 13s - loss: 0.8010 - dice_coeff: 0.6012 - acc: 0.6472\n",
      "Epoch 00004: acc did not improve from 0.70419\n",
      "5/5 [==============================] - 67s 13s/step - loss: 0.8032 - dice_coeff: 0.6022 - acc: 0.6566\n",
      "Epoch 5/5\n",
      "4/5 [=======================>......] - ETA: 13s - loss: 0.7351 - dice_coeff: 0.6198 - acc: 0.7009\n",
      "Epoch 00005: acc did not improve from 0.70419\n",
      "5/5 [==============================] - 69s 14s/step - loss: 0.7657 - dice_coeff: 0.6113 - acc: 0.6814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10e0d9bf5c8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.fit_generator(train_gen, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "166e0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class visualize(Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(f'\\nGenerating output at epoch : {epoch}')\n",
    "        i = 567\n",
    "        img = image.img_to_array(image.load_img(f'{image_list[i]}'))/255.    \n",
    "        dims = img.shape\n",
    "        x = cv2.resize(img, (256, 256))\n",
    "        x = np.float32(x)/255.\n",
    "        z = unet.predict(np.expand_dims(x, axis=0))\n",
    "        z = np.squeeze(z)\n",
    "        z = z.reshape(256, 256, 8)\n",
    "        z = cv2.resize(z, (dims[1], dims[0]))\n",
    "        y = np.argmax(z, axis=2)\n",
    "        \n",
    "        construction = np.zeros_like(y)\n",
    "        human = np.zeros_like(y)\n",
    "        vehicle = np.zeros_like(y)\n",
    "        construction[y==2] = 255.\n",
    "        human[y==6] = 255.\n",
    "        vehicle[y==7] = 255.\n",
    "        \n",
    "        result = img.copy()\n",
    "        alpha = 0.4\n",
    "        img[:,:,1] = construction\n",
    "        img[:,:,2] = vehicle \n",
    "        img[:,:,0] = human\n",
    "\n",
    "        cv2.addWeighted(img, alpha, result, 1-alpha, 0, result)\n",
    "        cv2.imwrite(f'outputs/{epoch}.png', cv2.cvtColor(result, cv2.COLOR_RGB2BGR))\n",
    "        print('Wrote file to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f53b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "939c33f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2432), started 0:01:55 ago. (Use '!kill 2432' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x24db2aaa248>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63a9dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7f1997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\favre\\projet_9\\test\n"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f732a173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 6 image(s) found.\n",
      "Output directory set to C:\\Users\\favre\\projet_9\\test\\augmented."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 ground truth image(s) found.\n",
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=256x256 at 0x24C239E6B08>: 100%|███| 15/15 [00:04<00:00,  3.25 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "new_image_dir = 'test/image'\n",
    "new_mask_dir = 'test/mask'\n",
    "output_dir = os.path.abspath('test/augmented')\n",
    "\n",
    "#build augmentor pipeline\n",
    "p = Augmentor.Pipeline(new_image_dir, output_dir)\n",
    "\n",
    "#add groud truth for pair modification\n",
    "p.ground_truth(new_mask_dir)\n",
    "\n",
    "#add operation\n",
    "p.rotate(probability=1, max_left_rotation=10, max_right_rotation=10)\n",
    "p.flip_left_right(probability=0.5)\n",
    "p.zoom_random(probability=0.5, percentage_area=0.8)\n",
    "p.skew(probability=0.5, magnitude=0.5)\n",
    "p.skew_tilt(probability=0.5, magnitude=0.5)\n",
    "p.random_distortion(probability=0.5,grid_height=4, grid_width=4, magnitude=4)\n",
    "p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
    "p.gaussian_distortion(probability=0.5, corner='bell', method='in', grid_height=4, grid_width=4, magnitude=4)\n",
    "p.skew_top_bottom(probability=0.5, magnitude=.5)\n",
    "p.skew_left_right(probability=0.5, magnitude=.5)\n",
    "p.skew_corner(probability=0.5, magnitude=.5)\n",
    "p.resize(probability=1,width=256, height=256)\n",
    "\n",
    "print('start sampling')\n",
    "p.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08fb45a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_dir = 'test/image'\n",
    "mask_dir = 'test/mask'\n",
    "aug_dir = 'test/augmented'\n",
    "\n",
    "image_list = []\n",
    "mask_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(mask_dir):\n",
    "    for name in files:\n",
    "        mask_list.append(os.path.join(root, name))\n",
    "        \n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for name in files:\n",
    "        image_list.append(os.path.join(root, name))\n",
    "\n",
    "for root, dirs, files in os.walk(aug_dir):\n",
    "    for name in files:\n",
    "        if 'groundtruth' in name:\n",
    "            mask_list.append(os.path.join(root, name))\n",
    "        else:\n",
    "            image_list.append(os.path.join(root, name))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b9bb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634aca43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e20a826d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/mask\\aachen_000000_000019.png \n",
      "\n",
      "test/mask\\aachen_000001_000019.png \n",
      "\n",
      "test/mask\\aachen_000002_000019.png \n",
      "\n",
      "test/mask\\aachen_000003_000019.png \n",
      "\n",
      "test/mask\\aachen_000004_000019.png \n",
      "\n",
      "test/mask\\aachen_000005_000019.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000000_000019.png_6ffb9fec-f80a-4a02-9e34-d36065d5b5ff.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000001_000019.png_011653eb-8368-4895-90f6-ba0ed7dbeed8.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000001_000019.png_56e8642c-ec1f-4c7d-89e5-d931d8ce05f3.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000001_000019.png_90464c97-3175-4b4b-be49-441e52fcbb03.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000001_000019.png_9d45ce92-457c-4e92-b147-af0606a91cdf.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000001_000019.png_fa216f30-27e3-4c4e-a749-1baa59af743e.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000002_000019.png_7c4ec104-c8ef-4fda-af2a-a94174c3955b.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000002_000019.png_884c824e-0ad3-4203-ab51-34d9e6e6cbb7.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000002_000019.png_f7bbf0fd-ce57-4cdd-a6f2-7e7a401c5d9c.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000003_000019.png_3e234931-0551-4598-aae2-476f043f8bd6.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000004_000019.png_14e2124b-bf2e-410c-ad38-07adfa96cb32.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000004_000019.png_f8415273-61d6-4447-a906-a78d008e18d9.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000005_000019.png_1c1b3095-a70f-48a1-a014-237bb3ed0287.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000005_000019.png_a10892f1-543e-4182-b4d2-9c192f2aadad.png \n",
      "\n",
      "test/augmented\\_groundtruth_(1)_image_aachen_000005_000019.png_ee420554-4c06-4b67-b564-6156ccf2d72f.png \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in mask_list:\n",
    "    print(item,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ae2365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/image\\aachen_000000_000019.png \n",
      "\n",
      "test/image\\aachen_000001_000019.png \n",
      "\n",
      "test/image\\aachen_000002_000019.png \n",
      "\n",
      "test/image\\aachen_000003_000019.png \n",
      "\n",
      "test/image\\aachen_000004_000019.png \n",
      "\n",
      "test/image\\aachen_000005_000019.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000000_000019.png_6ffb9fec-f80a-4a02-9e34-d36065d5b5ff.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000001_000019.png_011653eb-8368-4895-90f6-ba0ed7dbeed8.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000001_000019.png_56e8642c-ec1f-4c7d-89e5-d931d8ce05f3.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000001_000019.png_90464c97-3175-4b4b-be49-441e52fcbb03.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000001_000019.png_9d45ce92-457c-4e92-b147-af0606a91cdf.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000001_000019.png_fa216f30-27e3-4c4e-a749-1baa59af743e.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000002_000019.png_7c4ec104-c8ef-4fda-af2a-a94174c3955b.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000002_000019.png_884c824e-0ad3-4203-ab51-34d9e6e6cbb7.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000002_000019.png_f7bbf0fd-ce57-4cdd-a6f2-7e7a401c5d9c.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000003_000019.png_3e234931-0551-4598-aae2-476f043f8bd6.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000004_000019.png_14e2124b-bf2e-410c-ad38-07adfa96cb32.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000004_000019.png_f8415273-61d6-4447-a906-a78d008e18d9.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000005_000019.png_1c1b3095-a70f-48a1-a014-237bb3ed0287.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000005_000019.png_a10892f1-543e-4182-b4d2-9c192f2aadad.png \n",
      "\n",
      "test/augmented\\image_original_aachen_000005_000019.png_ee420554-4c06-4b67-b564-6156ccf2d72f.png \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in image_list:\n",
    "    print(item,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0b1fd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/mask\\\\aachen_000000_000019.png', 'test/mask\\\\aachen_000001_000019.png', 'test/mask\\\\aachen_000002_000019.png', 'test/mask\\\\aachen_000003_000019.png', 'test/mask\\\\aachen_000004_000019.png', 'test/mask\\\\aachen_000005_000019.png', 'test/mask\\\\aachen_000006_000019.png', 'test/mask\\\\aachen_000007_000019.png', 'test/mask\\\\aachen_000008_000019.png', 'test/mask\\\\aachen_000009_000019.png', 'test/mask\\\\aachen_000010_000019.png', 'test/mask\\\\aachen_000011_000019.png', 'test/mask\\\\aachen_000012_000019.png', 'test/mask\\\\aachen_000013_000019.png', 'test/mask\\\\aachen_000014_000019.png', 'test/mask\\\\aachen_000015_000019.png', 'test/mask\\\\aachen_000016_000019.png', 'test/mask\\\\aachen_000017_000019.png', 'test/mask\\\\aachen_000018_000019.png', 'test/mask\\\\aachen_000019_000019.png', 'test/mask\\\\aachen_000020_000019.png', 'test/mask\\\\aachen_000021_000019.png', 'test/mask\\\\aachen_000022_000019.png', 'test/mask\\\\aachen_000023_000019.png', 'test/mask\\\\aachen_000024_000019.png', 'test/mask\\\\aachen_000025_000019.png', 'test/mask\\\\aachen_000026_000019.png', 'test/mask\\\\aachen_000027_000019.png', 'test/mask\\\\aachen_000028_000019.png', 'test/mask\\\\aachen_000029_000019.png', 'test/mask\\\\aachen_000030_000019.png', 'test/mask\\\\aachen_000031_000019.png', 'test/mask\\\\aachen_000032_000019.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000002_000019.png_3673645a-d58e-4d4f-adad-b3a96425338e.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000003_000019.png_0a475df5-f046-471a-a74b-bb4b9b8b6b3e.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000006_000019.png_7078ec7c-4a18-475e-bd28-17a93f1c7fbd.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000008_000019.png_896492cf-17dc-46e5-8af9-ed5568857694.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000010_000019.png_103fc3fb-84c9-41fa-83c0-51dc90ee0f75.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000010_000019.png_eba6676e-27a1-4158-9060-7259fd201b0b.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000011_000019.png_1ffb7d57-c40f-40bb-b050-0b9da308008a.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000011_000019.png_6fc14e98-a603-4f17-b0b4-f2e3d487449f.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000012_000019.png_5b16df61-7550-4775-8da1-ad4288b7eb08.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000014_000019.png_819794ac-3902-4c2e-9b2e-c9d176680ccc.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000016_000019.png_6bcb35ab-abea-402b-86dc-6ba4aca51054.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000016_000019.png_b7a69475-dcb4-4cf3-a815-5e77b0d394c1.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000017_000019.png_f64fa8df-86d2-47c9-8da6-25d0341c68f6.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000018_000019.png_481fb6bf-0ee9-4eaf-adc4-b27713d2f713.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000020_000019.png_0435f8d4-c888-438b-a1b9-e77b5f90e18d.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000022_000019.png_48a7a90f-2a7c-4304-87a2-80bbfd562e9b.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000023_000019.png_a97b51ad-8777-4b4e-82e0-c0a95260f883.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000024_000019.png_2c6e12d3-766f-499f-8904-3eb6769e220a.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000025_000019.png_43923ca5-e287-407a-a363-11df2be6b819.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000025_000019.png_f19bb16d-8a88-4c9a-be57-4da02b06bd38.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000026_000019.png_52621e68-ae8f-48ee-a125-079c5e56e4e4.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000028_000019.png_190c4ec6-a0ae-4a85-a515-438a39e0c816.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000029_000019.png_1640d6a5-92c7-4b02-9f8e-a80a0629989f.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000029_000019.png_736e11ff-93e2-4bc7-b64f-161036f99eb6.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000029_000019.png_a3e331ee-a072-40f1-b75c-ce244447914a.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000029_000019.png_bf1422f4-1bf4-4e3b-8870-21350c80cd1a.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000030_000019.png_0e23264d-a06a-4db4-a2f7-aa1cc0c7005c.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000030_000019.png_889e7cfb-334c-4e8e-8d69-314ff6ba76be.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000031_000019.png_bc496d66-5c92-4dfd-99a1-9ccbfd5bf0e9.png', 'test/image\\\\output\\\\_groundtruth_(1)_image_aachen_000032_000019.png_791fbd2f-c7f2-43b2-88d6-9541bd4c8542.png']\n"
     ]
    }
   ],
   "source": [
    "print(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a41f933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/image\\\\aachen_000000_000019.png', 'test/image\\\\aachen_000001_000019.png', 'test/image\\\\aachen_000002_000019.png', 'test/image\\\\aachen_000003_000019.png', 'test/image\\\\aachen_000004_000019.png', 'test/image\\\\aachen_000005_000019.png', 'test/image\\\\aachen_000006_000019.png', 'test/image\\\\aachen_000007_000019.png', 'test/image\\\\aachen_000008_000019.png', 'test/image\\\\aachen_000009_000019.png', 'test/image\\\\aachen_000010_000019.png', 'test/image\\\\aachen_000011_000019.png', 'test/image\\\\aachen_000012_000019.png', 'test/image\\\\aachen_000013_000019.png', 'test/image\\\\aachen_000014_000019.png', 'test/image\\\\aachen_000015_000019.png', 'test/image\\\\aachen_000016_000019.png', 'test/image\\\\aachen_000017_000019.png', 'test/image\\\\aachen_000018_000019.png', 'test/image\\\\aachen_000019_000019.png', 'test/image\\\\aachen_000020_000019.png', 'test/image\\\\aachen_000021_000019.png', 'test/image\\\\aachen_000022_000019.png', 'test/image\\\\aachen_000023_000019.png', 'test/image\\\\aachen_000024_000019.png', 'test/image\\\\aachen_000025_000019.png', 'test/image\\\\aachen_000026_000019.png', 'test/image\\\\aachen_000027_000019.png', 'test/image\\\\aachen_000028_000019.png', 'test/image\\\\aachen_000029_000019.png', 'test/image\\\\aachen_000030_000019.png', 'test/image\\\\aachen_000031_000019.png', 'test/image\\\\aachen_000032_000019.png', 'test/image\\\\output\\\\image_original_aachen_000002_000019.png_3673645a-d58e-4d4f-adad-b3a96425338e.png', 'test/image\\\\output\\\\image_original_aachen_000003_000019.png_0a475df5-f046-471a-a74b-bb4b9b8b6b3e.png', 'test/image\\\\output\\\\image_original_aachen_000006_000019.png_7078ec7c-4a18-475e-bd28-17a93f1c7fbd.png', 'test/image\\\\output\\\\image_original_aachen_000008_000019.png_896492cf-17dc-46e5-8af9-ed5568857694.png', 'test/image\\\\output\\\\image_original_aachen_000010_000019.png_103fc3fb-84c9-41fa-83c0-51dc90ee0f75.png', 'test/image\\\\output\\\\image_original_aachen_000010_000019.png_eba6676e-27a1-4158-9060-7259fd201b0b.png', 'test/image\\\\output\\\\image_original_aachen_000011_000019.png_1ffb7d57-c40f-40bb-b050-0b9da308008a.png', 'test/image\\\\output\\\\image_original_aachen_000011_000019.png_6fc14e98-a603-4f17-b0b4-f2e3d487449f.png', 'test/image\\\\output\\\\image_original_aachen_000012_000019.png_5b16df61-7550-4775-8da1-ad4288b7eb08.png', 'test/image\\\\output\\\\image_original_aachen_000014_000019.png_819794ac-3902-4c2e-9b2e-c9d176680ccc.png', 'test/image\\\\output\\\\image_original_aachen_000016_000019.png_6bcb35ab-abea-402b-86dc-6ba4aca51054.png', 'test/image\\\\output\\\\image_original_aachen_000016_000019.png_b7a69475-dcb4-4cf3-a815-5e77b0d394c1.png', 'test/image\\\\output\\\\image_original_aachen_000017_000019.png_f64fa8df-86d2-47c9-8da6-25d0341c68f6.png', 'test/image\\\\output\\\\image_original_aachen_000018_000019.png_481fb6bf-0ee9-4eaf-adc4-b27713d2f713.png', 'test/image\\\\output\\\\image_original_aachen_000020_000019.png_0435f8d4-c888-438b-a1b9-e77b5f90e18d.png', 'test/image\\\\output\\\\image_original_aachen_000022_000019.png_48a7a90f-2a7c-4304-87a2-80bbfd562e9b.png', 'test/image\\\\output\\\\image_original_aachen_000023_000019.png_a97b51ad-8777-4b4e-82e0-c0a95260f883.png', 'test/image\\\\output\\\\image_original_aachen_000024_000019.png_2c6e12d3-766f-499f-8904-3eb6769e220a.png', 'test/image\\\\output\\\\image_original_aachen_000025_000019.png_43923ca5-e287-407a-a363-11df2be6b819.png', 'test/image\\\\output\\\\image_original_aachen_000025_000019.png_f19bb16d-8a88-4c9a-be57-4da02b06bd38.png', 'test/image\\\\output\\\\image_original_aachen_000026_000019.png_52621e68-ae8f-48ee-a125-079c5e56e4e4.png', 'test/image\\\\output\\\\image_original_aachen_000028_000019.png_190c4ec6-a0ae-4a85-a515-438a39e0c816.png', 'test/image\\\\output\\\\image_original_aachen_000029_000019.png_1640d6a5-92c7-4b02-9f8e-a80a0629989f.png', 'test/image\\\\output\\\\image_original_aachen_000029_000019.png_736e11ff-93e2-4bc7-b64f-161036f99eb6.png', 'test/image\\\\output\\\\image_original_aachen_000029_000019.png_a3e331ee-a072-40f1-b75c-ce244447914a.png', 'test/image\\\\output\\\\image_original_aachen_000029_000019.png_bf1422f4-1bf4-4e3b-8870-21350c80cd1a.png', 'test/image\\\\output\\\\image_original_aachen_000030_000019.png_0e23264d-a06a-4db4-a2f7-aa1cc0c7005c.png', 'test/image\\\\output\\\\image_original_aachen_000030_000019.png_889e7cfb-334c-4e8e-8d69-314ff6ba76be.png', 'test/image\\\\output\\\\image_original_aachen_000031_000019.png_bc496d66-5c92-4dfd-99a1-9ccbfd5bf0e9.png', 'test/image\\\\output\\\\image_original_aachen_000032_000019.png_791fbd2f-c7f2-43b2-88d6-9541bd4c8542.png']\n"
     ]
    }
   ],
   "source": [
    "print(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b9a0832",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23412/4087077924.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# sanity check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmask_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "for i in range(len(image_list)):\n",
    "    assert image_list[i] == mask_list[i]\n",
    "print(image_list[2], mask_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e847d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
